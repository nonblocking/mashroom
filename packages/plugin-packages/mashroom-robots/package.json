{
    "name": "@mashroom/mashroom-robots",
    "description": "Adds a middleware that exposes a robots.txt file for search engines",
    "homepage": "https://www.mashroom-server.com",
    "repository": "github:nonblocking/mashroom",
    "license": "MIT",
    "version": "2.4.1",
    "files": [
        "dist/**",
        "default-robots.txt"
    ],
    "devDependencies": {
        "@mashroom/mashroom": "2.4.1"
    },
    "jest": {
        "verbose": true,
        "testEnvironment": "node",
        "roots": [
            "<rootDir>/test"
        ],
        "testRegex": "(\\.(test|spec))\\.ts",
        "reporters": [
            "default",
            "jest-junit"
        ]
    },
    "jest-junit": {
        "outputDirectory": "./test-reports"
    },
    "scripts": {
        "lint": "eslint src --ext \".ts\" --fix",
        "type-check": "tsc --noEmit",
        "test": "jest",
        "build": "babel src -d dist --extensions \".ts\""
    },
    "mashroom": {
        "devModeBuildScript": "build",
        "plugins": [
            {
                "name": "Mashroom Robots Middleware",
                "type": "middleware",
                "bootstrap": "./dist/mashroom-bootstrap-middleware.js",
                "defaultConfig": {
                    "order": 300,
                    "robots.txt": null
                }
            }
        ]
    }
}
